{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = pd.read_csv('../data/features.csv')\n",
    "df_sales = pd.read_csv('../data/sales.csv')\n",
    "df_stores = pd.read_csv('../data/stores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features['Date'] = pd.to_datetime(df_features['Date'], format='%d/%m/%Y')\n",
    "df_sales['Date'] = pd.to_datetime(df_sales['Date'], format='%d/%m/%Y')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = df_features.rename(columns={'IsHoliday': 'IsHolidayFeatures'})\n",
    "df_combined = pd.merge(df_sales, df_stores, on='Store', how='left')\n",
    "df_final = pd.merge(df_combined, df_features, on=['Store', 'Date'], how='left')\n",
    "df_final['week'] = df_final['Date'].dt.isocalendar().week\n",
    "df_final['month'] = df_final['Date'].dt.month\n",
    "df_final['day'] = df_final['Date'].dt.day\n",
    "df_final.set_index('Date', inplace=True)\n",
    "df_final = df_final.sort_index()\n",
    "df_final.drop(columns=['IsHolidayFeatures'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv('../data/combined_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_forecasting_features_year(df):\n",
    "    df = df.copy()\n",
    "    shiftable_columns = ['Weekly_Sales', 'Temperature', 'MarkDown1','Fuel_Price',\n",
    "                        'MarkDown2', 'MarkDown3', 'MarkDown4', \n",
    "                        'MarkDown5', 'CPI', 'Unemployment']\n",
    "    dropable_columns  = ['Temperature', 'MarkDown1','Fuel_Price',\n",
    "                        'MarkDown2', 'MarkDown3', 'MarkDown4', \n",
    "                        'MarkDown5', 'CPI', 'Unemployment']\n",
    "    for col in shiftable_columns:\n",
    "        df[f'lag_yearly_{col}'] = df.groupby(['Store', 'Dept'])[col].shift(52)\n",
    "        df[f'{col}_historical_week_avg'] = df.groupby(\n",
    "            ['Store', 'Dept', 'week']\n",
    "        )[f'lag_yearly_{col}'].transform('mean')\n",
    "    feature_df = df.drop(dropable_columns, axis=1)\n",
    "    df_clean = feature_df.dropna(subset=['lag_yearly_Weekly_Sales'])\n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_forecasting_features_4_weeks(df):\n",
    "    df = df.copy()\n",
    "    shiftable_columns = ['Weekly_Sales', 'Temperature', 'MarkDown1', 'Fuel_Price',\n",
    "                         'MarkDown2', 'MarkDown3', 'MarkDown4', \n",
    "                         'MarkDown5', 'CPI', 'Unemployment']\n",
    "    dropable_columns = ['Temperature', 'MarkDown1', 'Fuel_Price',\n",
    "                        'MarkDown2', 'MarkDown3', 'MarkDown4', \n",
    "                        'MarkDown5', 'CPI', 'Unemployment']\n",
    "    \n",
    "    lags = [4, 8, 16, 32]\n",
    "    for lag in lags:\n",
    "        for col in shiftable_columns:\n",
    "            df[f'lag_{lag}_{col}'] = df.groupby(['Store', 'Dept'])[col].shift(lag)\n",
    "\n",
    "    \n",
    "    for col in shiftable_columns:\n",
    "        df[f'{col}_historical_week_avg'] = df.groupby(['Store', 'Dept', 'week'])[col].transform('mean')\n",
    "    \n",
    "    feature_df = df.drop(dropable_columns, axis=1)\n",
    "    df_clean = feature_df.dropna(subset=['lag_32_Weekly_Sales'])\n",
    "    return df_clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_year_prediction = prepare_forecasting_features_year(df_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4_weeks_prediction = prepare_forecasting_features_4_weeks(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_year_prediction.to_csv('../data/year_lag_data.csv')\n",
    "df_4_weeks_prediction.to_csv('../data/4_weeks_lag_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "store =  df[(df['Store'] == 1) & (df['Dept'] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "store.to_csv('1.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
